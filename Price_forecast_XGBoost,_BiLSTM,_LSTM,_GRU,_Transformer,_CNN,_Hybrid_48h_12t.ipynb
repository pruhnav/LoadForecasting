{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pruhnav/LoadForecasting/blob/main/Price_forecast_XGBoost%2C_BiLSTM%2C_LSTM%2C_GRU%2C_Transformer%2C_CNN%2C_Hybrid_48h_12t.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePi6_5p-ePj0"
      },
      "source": [
        "# Energy Price Prediction with XGBoost & BiLSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8uQdVGfEihJ"
      },
      "source": [
        "# Task for reza\n",
        "- Make the progam to forecast 24 hours of prices at once.\n",
        "- Change the input from t = 24, 24*3, 24*5, 24*7, 24*9, 24*11.\n",
        "- Input for others 24*7, Output t = 24.\n",
        "- See link: https://ieeexplore-ieee-org.ezaccess.libraries.psu.edu/stamp/stamp.jsp?tp=&arnumber=10214317\n",
        "- Create Fig. 10 for MAE (Mean Absulute Error) and RMSE (Root Mean Squared Error) for Test data set (Proposed Hybrid Model).\n",
        "- Two cases comparison (Actual vs Predcited): Best and Worst week.\n",
        "- Whole year (2023) Actual vs Predicted and (Residual = Actual - Predicted)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VuTDeulj4Aqm"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Open file upload dialog\n",
        "#uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "BCGZZ4JYBs8Z",
        "outputId": "1c3ba313-43a7-43e4-9b95-d3d3271c95d7"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'day_ahead_energy_prices.xlsx'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-c9cd1da75256>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load the uploaded Excel file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'day_ahead_energy_prices.xlsx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Display the first few rows of the DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         io = ExcelFile(\n\u001b[0m\u001b[1;32m    496\u001b[0m             \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   1548\u001b[0m                 \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xls\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1549\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1550\u001b[0;31m                 ext = inspect_excel_format(\n\u001b[0m\u001b[1;32m   1551\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1400\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1402\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m   1403\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m     ) as handle:\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'day_ahead_energy_prices.xlsx'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the uploaded Excel file\n",
        "df = pd.read_excel('day_ahead_energy_prices.xlsx')\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TIjR_98rBupU"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EnmPdB9-B8Ka"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iR50BY04la5n"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from xgboost import XGBRegressor\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Bidirectional, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RgSlW796YTRv"
      },
      "outputs": [],
      "source": [
        "# Assuming `df` is your DataFrame containing 'Date' and 'Price'\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "df.set_index('Date', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GGkm6M7VlXgp"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Data Preprocessing\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_data = scaler.fit_transform(df['Price'].values.reshape(-1, 1))\n",
        "\n",
        "# Create data structure for BiLSTM\n",
        "def create_dataset(data, time_step=60):\n",
        "    X, y = [], []\n",
        "    for i in range(time_step, len(data)):\n",
        "        X.append(data[i-time_step:i, 0])\n",
        "        y.append(data[i, 0])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "def prepare_data(data, look_back=48, look_ahead=1):\n",
        "  X, y = [], []\n",
        "  for i in range(len(data) - look_back - look_ahead + 1):\n",
        "    X.append(data[i:(i + look_back)])\n",
        "    y.append(data[(i + look_back):(i + look_back + look_ahead)])\n",
        "  return np.array(X), np.array(y)\n",
        "\n",
        "\n",
        "#X, y = create_dataset(scaled_data)\n",
        "X, y = prepare_data(scaled_data)\n",
        "X.shape,y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IniBWsleY0SJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ddk6CQUeYacS"
      },
      "outputs": [],
      "source": [
        "X = X.reshape(X.shape[0], X.shape[1], 1)  # Reshape for BiLSTM input\n",
        "\n",
        "# Split into training and testing sets based on year\n",
        "train_df = df[df.index.year <= 2022]\n",
        "test_df = df[df.index.year == 2023]\n",
        "train_scaled = scaler.transform(train_df['Price'].values.reshape(-1, 1))\n",
        "test_scaled = scaler.transform(test_df['Price'].values.reshape(-1, 1))\n",
        "\n",
        "X_train, y_train = prepare_data(train_scaled)\n",
        "X_test, y_test = prepare_data(test_scaled)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9qXWA9VxaFQn"
      },
      "outputs": [],
      "source": [
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mgPaN1RslcjI"
      },
      "outputs": [],
      "source": [
        "print(X_train.shape,y_train.shape)\n",
        "print(X_test.shape,y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KpJITzegE6BV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZF4W_zGK-W3"
      },
      "outputs": [],
      "source": [
        "EPOCH = 3 # change here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i050zmtrl3CA"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Build BiLSTM Model\n",
        "def build_bilstm_model(input_shape, lstm_units=64, dropout_rate=0.2):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = Bidirectional(LSTM(lstm_units, return_sequences=False))(inputs)\n",
        "\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "    outputs = Dense(12)(x)\n",
        "    model = Model(inputs, outputs)\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "    return model\n",
        "\n",
        "bilstm_model = build_bilstm_model(input_shape=(X_train.shape[1], X_train.shape[2]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: create xgboost model function\n",
        "\n",
        "def create_xgboost_model(X_train, y_train):\n",
        "  \"\"\"Creates and trains an XGBoost model.\n",
        "\n",
        "  Args:\n",
        "    X_train: Training input data.\n",
        "    y_train: Training target data.\n",
        "\n",
        "  Returns:\n",
        "    Trained XGBoost model.\n",
        "  \"\"\"\n",
        "  xgb_model = XGBRegressor(objective='reg:squarederror', n_estimators=100, learning_rate=0.1)\n",
        "  xgb_model.fit(X_train.reshape(X_train.shape[0], -1), y_train.reshape(y_train.shape[0], -1))\n",
        "  return xgb_model\n"
      ],
      "metadata": {
        "id": "Chbi2dkFxhfu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-6d3cvXCOoV"
      },
      "outputs": [],
      "source": [
        "# Train BiLSTM\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "bilstm_model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=EPOCH,\n",
        "    batch_size=32,\n",
        "    callbacks=[early_stopping]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bWfzyhP7l3tn"
      },
      "outputs": [],
      "source": [
        "# prompt: see layers of bilstm_model\n",
        "\n",
        "bilstm_model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: apply the bilstm model and give the mse, rmse, mae, smape, and r^2 score\n",
        "\n",
        "# Predict using BiLSTM\n",
        "y_pred_bilstm = bilstm_model.predict(X_test)\n",
        "\n",
        "# Inverse transform the predictions and actual values\n",
        "y_test_inv = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
        "y_pred_bilstm_inv = scaler.inverse_transform(y_pred_bilstm.reshape(-1, 1))\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "mse_bilstm = mean_squared_error(y_test_inv, y_pred_bilstm_inv)\n",
        "rmse_bilstm = np.sqrt(mse_bilstm)\n",
        "mae_bilstm = mean_absolute_error(y_test_inv, y_pred_bilstm_inv)\n",
        "\n",
        "# SMAPE calculation\n",
        "def smape(A, F):\n",
        "    return 100/len(A) * np.sum(2 * np.abs(F - A) / (np.abs(A) + np.abs(F)))\n",
        "\n",
        "smape_bilstm = smape(y_test_inv, y_pred_bilstm_inv)\n",
        "\n",
        "r2_bilstm = r2_score(y_test_inv, y_pred_bilstm_inv)\n",
        "\n",
        "print(f\"BiLSTM - MSE: {mse_bilstm:.4f}\")\n",
        "print(f\"BiLSTM - RMSE: {rmse_bilstm:.4f}\")\n",
        "print(f\"BiLSTM - MAE: {mae_bilstm:.4f}\")\n",
        "print(f\"BiLSTM - SMAPE: {smape_bilstm:.4f}\")\n",
        "print(f\"BiLSTM - R^2 Score: {r2_bilstm:.4f}\")\n"
      ],
      "metadata": {
        "id": "dH7XfH0QMqDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: apply the xgboost model and give the mse, rmse, mae, smape, and r^2 score\n",
        "\n",
        "# Train XGBoost\n",
        "xgb_model = create_xgboost_model(X_train, y_train)\n",
        "\n",
        "# Predict using XGBoost\n",
        "y_pred_xgb = xgb_model.predict(X_test.reshape(X_test.shape[0], -1))\n",
        "\n",
        "\n",
        "# Inverse transform the predictions and actual values\n",
        "y_test_inv = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
        "y_pred_xgb_inv = scaler.inverse_transform(y_pred_xgb.reshape(-1, 1))\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "mse_xgb = mean_squared_error(y_test_inv, y_pred_xgb_inv)\n",
        "rmse_xgb = np.sqrt(mse_xgb)\n",
        "mae_xgb = mean_absolute_error(y_test_inv, y_pred_xgb_inv)\n",
        "smape_xgb = smape(y_test_inv, y_pred_xgb_inv)\n",
        "r2_xgb = r2_score(y_test_inv, y_pred_xgb_inv)\n",
        "\n",
        "print(f\"XGBoost - MSE: {mse_xgb:.4f}\")\n",
        "print(f\"XGBoost - RMSE: {rmse_xgb:.4f}\")\n",
        "print(f\"XGBoost - MAE: {mae_xgb:.4f}\")\n",
        "print(f\"XGBoost - SMAPE: {smape_xgb:.4f}\")\n",
        "print(f\"XGBoost - R^2 Score: {r2_xgb:.4f}\")\n"
      ],
      "metadata": {
        "id": "hhJ3ZNZYM5Mr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "lstm_model = Sequential()\n",
        "lstm_model.add(LSTM(64, activation='relu', input_shape=(48, 1)))  # assuming univariate input\n",
        "lstm_model.add(Dense(12))  # 6-hour forecast\n",
        "lstm_model.compile(optimizer='adam', loss='mse')\n",
        "lstm_model.summary()\n",
        "\n",
        "# Train the model\n",
        "lstm_model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.1)\n"
      ],
      "metadata": {
        "id": "QGlnnpLEIIpr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import GRU\n",
        "\n",
        "gru_model = Sequential()\n",
        "gru_model.add(GRU(64, activation='relu', input_shape=(48, 12)))\n",
        "gru_model.add(Dense(1))\n",
        "gru_model.compile(optimizer='adam', loss='mse')\n",
        "gru_model.summary()\n",
        "\n",
        "gru_model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.1)\n"
      ],
      "metadata": {
        "id": "UBpO7UKIKKSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Dense, LayerNormalization, Dropout, MultiHeadAttention, GlobalAveragePooling1D\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "inputs = Input(shape=(48, 12))\n",
        "x = Dense(64)(inputs)\n",
        "x = MultiHeadAttention(num_heads=2, key_dim=32)(x, x)\n",
        "x = LayerNormalization()(x)\n",
        "x = Dropout(0.1)(x)\n",
        "x = GlobalAveragePooling1D()(x)\n",
        "outputs = Dense(1)(x)\n",
        "\n",
        "transformer_model = Model(inputs, outputs)\n",
        "transformer_model.compile(optimizer='adam', loss='mse')\n",
        "transformer_model.summary()\n",
        "\n",
        "transformer_model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.1)\n"
      ],
      "metadata": {
        "id": "AL6lyyEZKN6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten\n",
        "\n",
        "cnn_model = Sequential()\n",
        "cnn_model.add(Conv1D(64, kernel_size=3, activation='relu', input_shape=(48, 1)))\n",
        "cnn_model.add(MaxPooling1D(pool_size=2))\n",
        "cnn_model.add(Flatten())\n",
        "cnn_model.add(Dense(64, activation='relu'))\n",
        "cnn_model.add(Dense(1))\n",
        "cnn_model.compile(optimizer='adam', loss='mse')\n",
        "cnn_model.summary()\n",
        "\n",
        "cnn_model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.1)\n"
      ],
      "metadata": {
        "id": "2otp8spoKP0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "def smape(y_true, y_pred):\n",
        "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2.0\n",
        "    diff = np.abs(y_true - y_pred) / denominator\n",
        "    diff[denominator == 0] = 0.0\n",
        "    return 100 * np.mean(diff)\n",
        "\n",
        "def evaluate_model(model, X_test, y_test, scaler=None, model_name=\"Model\"):\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    y_test = np.squeeze(y_test)\n",
        "    y_pred = np.squeeze(y_pred)\n",
        "\n",
        "    # Inverse scale if scaler is given\n",
        "    if scaler:\n",
        "        y_test = scaler.inverse_transform(y_test.reshape(-1, 1)).reshape(y_test.shape)\n",
        "        y_pred = scaler.inverse_transform(y_pred.reshape(-1, 1)).reshape(y_pred.shape)\n",
        "\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    smape_score = smape(y_test, y_pred)\n",
        "\n",
        "    print(f\"{model_name} - MSE: {mse:.4f}\")\n",
        "    print(f\"{model_name} - RMSE: {rmse:.4f}\")\n",
        "    print(f\"{model_name} - MAE: {mae:.4f}\")\n",
        "    print(f\"{model_name} - SMAPE: {smape_score:.2f}%\")\n",
        "    print(f\"{model_name} - R^2 Score: {r2:.4f}\")\n"
      ],
      "metadata": {
        "id": "ZkbpUsAeKRGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model(lstm_model, X_test, y_test, scaler=scaler, model_name=\"LSTM\")\n",
        "evaluate_model(gru_model, X_test, y_test, scaler=scaler, model_name=\"GRU\")\n",
        "evaluate_model(transformer_model, X_test, y_test, scaler=scaler, model_name=\"Transformer\")\n",
        "evaluate_model(cnn_model, X_test, y_test, scaler=scaler, model_name=\"CNN\")\n"
      ],
      "metadata": {
        "id": "ECbJWMfsKTSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3D7vw3g40Ccr"
      },
      "source": [
        "### Task - HYBRID MODEL\n",
        "input 24, 48, 72, 96\n",
        "\n",
        "change the feature to 30, 60, 90, 120"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_vC9ytpmZIg"
      },
      "outputs": [],
      "source": [
        "# Extract Features from BiLSTM\n",
        "intermediate_layer_model = Model(inputs=bilstm_model.input, outputs=bilstm_model.layers[-2].output)\n",
        "bilstm_features_train = intermediate_layer_model.predict(X_train)\n",
        "bilstm_features_test = intermediate_layer_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmzLwA1xmjvn"
      },
      "outputs": [],
      "source": [
        "bilstm_features_train.shape,bilstm_features_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tx0VKc-IYDuw"
      },
      "outputs": [],
      "source": [
        "# sMAPE Calculation\n",
        "def calculate_smape(y_true, y_pred):\n",
        "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2.0\n",
        "    diff = np.abs(y_true - y_pred) / denominator\n",
        "    diff[denominator == 0] = 0.0  # handle the case where both prediction and actual are zero\n",
        "    return 100 * np.mean(diff)\n",
        "\n",
        "\n",
        "\n",
        "# Modified MAPE Calculation (exclude zero values in actual prices)\n",
        "def calculate_mape(y_true, y_pred):\n",
        "    non_zero_mask = y_true != 0  # Exclude zero actual values\n",
        "    y_true = y_true[non_zero_mask]\n",
        "    y_pred = y_pred[non_zero_mask]\n",
        "    return 100 * np.mean(np.abs((y_true - y_pred) / y_true))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_data = pd.DataFrame(columns=['Model', 'MAPE', 'RMSE', 'MAE', 'R2'])\n",
        "def evaluation_metrics(y_test_original, y_pred_original, model_name=\"No Model\"):\n",
        "  mae = mean_absolute_error(y_test_original, y_pred_original)\n",
        "  rmse = np.sqrt(mean_squared_error(y_test_original, y_pred_original))\n",
        "  mape = mean_absolute_percentage_error(y_test_original, y_pred_original)\n",
        "  r2 = r2_score(y_test_original, y_pred_original)\n",
        "\n",
        "\n",
        "  #print(f\"Mean Absolute Percentage Error (MAPE): {mape*100}\")\n",
        "  #print(f\"RMSE: {rmse}\")\n",
        "  #print(f\"Mean Absolute Error (MAE): {mae}\")\n",
        "  #print(f\"R-squared (R2): {r2}\")\n",
        "  # Create a new row as a dictionary\n",
        "  new_row = {'Model': model_name, 'MAPE': mape*100 , 'RMSE': rmse , 'MAE': mae , 'R2': r2 }\n",
        "  global evaluation_data;\n",
        "  # Add the new row using the loc indexer\n",
        "  evaluation_data.loc[model_name] = new_row\n",
        "  #print(evaluation_data)"
      ],
      "metadata": {
        "id": "RAmU3HdTAcdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_percentage_error"
      ],
      "metadata": {
        "id": "nK5ontZACi2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUH03M6MCA4O"
      },
      "outputs": [],
      "source": [
        "# Train XGBoost with BiLSTM Features\n",
        "xgb_model = XGBRegressor(n_estimators=100, learning_rate=0.05, max_depth=6, random_state=42)\n",
        "y_train_reshaped = y_train.reshape(y_train.shape[0], -1)  # Reshape to (num_samples, 24)\n",
        "xgb_model.fit(bilstm_features_train, y_train_reshaped, verbose=True)\n",
        "\n",
        "\n",
        "\n",
        "# Save Actual vs Predicted Prices in Excel\n",
        "#results_df = pd.DataFrame({\n",
        " #   'Date': test_df.index[-len(xgb_predictions):],\n",
        "  #  'Actual Price': test_actual.flatten(),\n",
        "   # 'Predicted Price': xgb_predictions_rescaled.flatten()\n",
        "#})\n",
        "#results_df.to_excel('actual_vs_predicted.xlsx', index=False)\n",
        "#print(\"Actual vs Predicted saved to 'actual_vs_predicted.xlsx'.\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Make Predictions with XGBoost\n",
        "xgb_predictions = xgb_model.predict(bilstm_features_test)\n",
        "xgb_predictions_rescaled = scaler.inverse_transform(xgb_predictions.reshape(-1, 6))\n",
        "\n",
        "# Rescale Test Data\n",
        "test_actual = scaler.inverse_transform(y_test.reshape(-1, 6))"
      ],
      "metadata": {
        "id": "2iJElCRhDAct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_metrics(test_actual, xgb_predictions_rescaled, f\"XGBoost_look_back_48_hour\")\n",
        "evaluation_data"
      ],
      "metadata": {
        "id": "s5c28ys2AmyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_actual"
      ],
      "metadata": {
        "id": "npnPsylLEPkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_predictions_rescaled"
      ],
      "metadata": {
        "id": "4aWJeOuYFG_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: find the difference between test_actual and xgb_predictions_rescaled where  every item comparison difference is more than 10\n",
        "\n",
        "# Find differences greater than 10\n",
        "differences = np.abs(test_actual - xgb_predictions_rescaled)\n",
        "indices = np.where(differences > 10)\n",
        "\n",
        "# Print the indices and values where the difference is greater than 10\n",
        "print(\"Indices where the difference is greater than 10:\")\n",
        "print(indices)\n",
        "\n",
        "print(\"\\nDifferences greater than 10:\")\n",
        "print(differences[indices])\n",
        "\n",
        "# Access the corresponding values from test_actual and xgb_predictions_rescaled\n",
        "print(\"\\nValues from test_actual:\")\n",
        "print(test_actual[indices])\n",
        "\n",
        "print(\"\\nValues from xgb_predictions_rescaled:\")\n",
        "xgb_predictions_rescaled[indices]\n"
      ],
      "metadata": {
        "id": "znX85CJaBs83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation Metrics\n",
        "mse = mean_squared_error(test_actual, xgb_predictions_rescaled)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(test_actual, xgb_predictions_rescaled)\n",
        "r2 = r2_score(test_actual, xgb_predictions_rescaled)\n",
        "\n",
        "smape = calculate_smape(test_actual, xgb_predictions_rescaled)\n",
        "\n",
        "mape = mean_absolute_percentage_error(test_actual, xgb_predictions_rescaled)\n",
        "\n",
        "print(f\"Hybrid Model Evaluation:\\nMAE: {mae}, RMSE: {rmse}, sMAPE: {smape}%, MAPE: {mape}, R^2: {r2}, MSE: {mse}\")\n"
      ],
      "metadata": {
        "id": "qpG43TNpCuZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: draw a line graph based test_actual and xgb_predictions_rescaled data every 24 data\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming xgb_predictions_rescaled and test_actual are already defined\n",
        "\n",
        "# Plotting every 24th data point\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(test_actual.flatten()[10000:20000:24], label='Actual')\n",
        "plt.plot(xgb_predictions_rescaled.flatten()[10000:20000:24], label='Predicted')\n",
        "plt.xlabel('Time Step (every 24)')\n",
        "plt.ylabel('Energy Price')\n",
        "plt.title('Actual vs Predicted Energy Prices (every 24 data points)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "jKRk7UyFAzOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGDET-Yu3tIO"
      },
      "outputs": [],
      "source": [
        "# Visualization\n",
        "SHOW_TEST_VALUES = 400\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.plot(test_df.index[-SHOW_TEST_VALUES:], test_actual[-SHOW_TEST_VALUES:], label='Actual Price')\n",
        "plt.plot(test_df.index[-SHOW_TEST_VALUES:], xgb_predictions_rescaled[-SHOW_TEST_VALUES:], label='Predicted Price')\n",
        "plt.title('Energy Price Prediction using Hybrid XGBoost-BiLSTM')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Price')\n",
        "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))#'%Y-%m-%d %H:%M\n",
        "plt.gca().xaxis.set_major_locator(mdates.DayLocator(interval=3))\n",
        "plt.gcf().autofmt_xdate()\n",
        "plt.legend()\n",
        "plt.savefig(\"Energy Price Prediction(proposed).pdf\", bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQ4i_z248xxn"
      },
      "outputs": [],
      "source": [
        "print(\"Extracted Features (Training):\")\n",
        "print(bilstm_features_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hY3KPsfL9DSl"
      },
      "outputs": [],
      "source": [
        "training_features_df = pd.DataFrame(bilstm_features_train)\n",
        "# training_features_df.to_excel('bilstm_features_train.xlsx', index=False) %%\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIdufEnLbXKW"
      },
      "source": [
        "To apply SHAP (SHapley Additive exPlanations) to a hybrid model combining BiLSTM and XGBoost, you need to follow a structured approach depending on how you integrate both models. Typically, this hybrid approach consists of two stages:\n",
        "\n",
        "Feature Extraction using BiLSTM: A BiLSTM (Bidirectional Long Short-Term Memory) network processes sequential data and extracts meaningful features.\n",
        "Prediction using XGBoost: The extracted features are then passed to an XGBoost model for final predictions.\n",
        "## Applying SHAP to this Hybrid Model\n",
        "Since SHAP explanations depend on the model type, you need to determine whether to explain the BiLSTM model, the XGBoost model, or both"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1gQV3k6IyiiY"
      },
      "outputs": [],
      "source": [
        "import shap\n",
        "# Explain XGBoost predictions using SHAP values\n",
        "explainer = shap.Explainer(xgb_model)\n",
        "shap_values = explainer(bilstm_features_test)\n",
        "\n",
        "# Visualize SHAP values\n",
        "shap.summary_plot(shap_values, bilstm_features_test, plot_type=\"bar\",max_display=10,show=False)\n",
        "plt.savefig(\"shap_summary_plot_bilstm_features_bar_graph.pdf\", bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8biDE3XNB21R"
      },
      "outputs": [],
      "source": [
        "\n",
        "shap.summary_plot(shap_values, bilstm_features_test,max_display=10,show=False)\n",
        "plt.savefig(\"shap_summary_plot_bilstm_features.pdf\", bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N5Ogll5yVH5V"
      },
      "outputs": [],
      "source": [
        "X_train_temp = X_train.reshape(X_train.shape[0],-1)\n",
        "X_test_temp = X_test.reshape(X_test.shape[0],-1)\n",
        "num_features = X_train_temp.shape[1]\n",
        "\n",
        "# Generate column names (Modify this based on actual feature names)\n",
        "feature_names = [f\"t-{60-i}\" for i in range(num_features)]  # Default names\n",
        "X_train_df = pd.DataFrame(X_train_temp, columns=feature_names)\n",
        "X_test_df = pd.DataFrame(X_test_temp, columns=feature_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhyir8WqSrK-"
      },
      "outputs": [],
      "source": [
        "NUM_ROWS = 500\n",
        "explainer_bilstm = shap.Explainer(bilstm_model, X_train_df[:NUM_ROWS])  # Sample subset for efficiency\n",
        "shap_values_bilstm = explainer_bilstm(X_test_df[:NUM_ROWS])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ossFCP9Rv_VN"
      },
      "outputs": [],
      "source": [
        "#shap.summary_plot(shap_values_bilstm, X_test_df, plot_type=\"bar\",max_display=10,show=False)\n",
        "\n",
        "#plt.savefig(\"shap_summary_plot_bilstm_average_impact.pdf\", bbox_inches='tight')\n",
        "#plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHW4m8wMhwWl"
      },
      "outputs": [],
      "source": [
        "# Visualize the SHAP values for BiLSTM\n",
        "\n",
        "shap.summary_plot(shap_values_bilstm, X_test_df[:NUM_ROWS], max_display=10,show=False)\n",
        "\n",
        "\n",
        "plt.savefig(\"shap_summary_plot_bilstm_impact_on_model_output.pdf\", bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "#t-1, t-2 ....."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cJjx8moW9EI"
      },
      "outputs": [],
      "source": [
        "shap.plots.waterfall(shap_values_bilstm[1],show=False)\n",
        "\n",
        "\n",
        "plt.savefig(\"shap_summary_plot_bilstm_waterfall.pdf\", bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JpWeIiF1XdMF"
      },
      "outputs": [],
      "source": [
        "shap.plots.bar(shap_values_bilstm,show=False)\n",
        "plt.savefig(\"shap_summary_plot_bilstm_mean_shap_value.pdf\", bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V09irXycdo4l"
      },
      "outputs": [],
      "source": [
        "\n",
        "explainer_bilstm = shap.Explainer(bilstm_model, X_train_df[:10])\n",
        "shap_values_bilstm = explainer_bilstm(X_test_df[:10])\n",
        "\n",
        "# Instead of using explainer_bilstm.model.predict, use your original model:\n",
        "expected_value = bilstm_model.predict(X_train_df[:10]).mean()\n",
        "\n",
        "shap.decision_plot(expected_value, shap_values_bilstm[1].values, X_test_df.columns,show=False)\n",
        "plt.savefig(\"shap_summary_plot_bilstm_model_output.pdf\", bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97lyk128_71n"
      },
      "outputs": [],
      "source": [
        "shap.plots.beeswarm(shap_values_bilstm)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}